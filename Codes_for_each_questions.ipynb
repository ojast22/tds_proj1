{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYcwVxoRAatQQvexqY35K1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Fk9AfkQCbZs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Who are the top 5 users in Delhi with the highest number of followers? List their login in order, comma-separated.\n",
        "Users"
      ],
      "metadata": {
        "id": "VPOnwC81Ciio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the list to store users from Delhi\n",
        "users_in_delhi = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        location = row['location'].strip().lower()\n",
        "        # Check if the user is from Delhi\n",
        "        if 'delhi' in location:\n",
        "            users_in_delhi.append({\n",
        "                'login': row['login'],\n",
        "                'followers': int(row['followers'])\n",
        "            })\n",
        "\n",
        "# Sort users based on followers in descending order\n",
        "top_users = sorted(users_in_delhi, key=lambda x: x['followers'], reverse=True)\n",
        "\n",
        "# Extract the top 5 user logins\n",
        "top_5_logins = [user['login'] for user in top_users[:5]]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(','.join(top_5_logins))\n"
      ],
      "metadata": {
        "id": "cOHZXvK5Dzyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Who are the 5 earliest registered GitHub users in Delhi? List their login in ascending order of created_at, comma-separated.\n",
        "Users"
      ],
      "metadata": {
        "id": "r_RB7TmyCncD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the list to store users from Delhi\n",
        "users_in_delhi = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        location = row['location'].strip().lower()\n",
        "        # Check if the user is from Delhi\n",
        "        if 'delhi' in location:\n",
        "            users_in_delhi.append({\n",
        "                'login': row['login'],\n",
        "                'created_at': datetime.strptime(row['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "            })\n",
        "\n",
        "# Sort users based on created_at in ascending order\n",
        "sorted_users = sorted(users_in_delhi, key=lambda x: x['created_at'])\n",
        "\n",
        "# Extract the top 5 user logins\n",
        "top_5_earliest_logins = [user['login'] for user in sorted_users[:5]]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(','.join(top_5_earliest_logins))\n"
      ],
      "metadata": {
        "id": "4WdKndbmD3kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3 What are the 3 most popular license among these users? Ignore missing licenses. List the license_name in order, comma-separated.\n",
        "Licenses"
      ],
      "metadata": {
        "id": "GIfCg2UvCx6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Define the list to store license names\n",
        "licenses = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        # Check if the license_name field is present and not empty\n",
        "        license_name = row.get('license_name', '').strip()\n",
        "        if license_name:\n",
        "            licenses.append(license_name)\n",
        "\n",
        "# Count the occurrence of each license\n",
        "license_counts = Counter(licenses)\n",
        "\n",
        "# Get the 3 most common licenses\n",
        "top_3_licenses = [license for license, count in license_counts.most_common(3)]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(','.join(top_3_licenses))\n"
      ],
      "metadata": {
        "id": "dRLym63cD_Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4 Which company do the majority of these developers work at?\n",
        "Company (cleaned up as explained above)"
      ],
      "metadata": {
        "id": "noYvPmNeC28Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Define the list to store company names\n",
        "companies = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        # Get and clean up the company field (ignore empty values)\n",
        "        company = row.get('company', '').strip()\n",
        "        if company:\n",
        "            companies.append(company)\n",
        "\n",
        "# Count the occurrence of each company\n",
        "company_counts = Counter(companies)\n",
        "\n",
        "# Find the most common company\n",
        "most_common_company = company_counts.most_common(1)\n",
        "\n",
        "# Print the result\n",
        "if most_common_company:\n",
        "    print(most_common_company[0][0])\n",
        "else:\n",
        "    print(\"No company data found.\")\n"
      ],
      "metadata": {
        "id": "56wg0FMsEBfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5 Which programming language is most popular among these users?\n",
        "Language"
      ],
      "metadata": {
        "id": "XaANYrWaC9Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Define the list to store programming languages\n",
        "languages = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        # Get and clean up the language field (ignore empty values)\n",
        "        language = row.get('language', '').strip()\n",
        "        if language:\n",
        "            languages.append(language)\n",
        "\n",
        "# Count the occurrence of each language\n",
        "language_counts = Counter(languages)\n",
        "\n",
        "# Find the most common language\n",
        "most_common_language = language_counts.most_common(1)\n",
        "\n",
        "# Print the result\n",
        "if most_common_language:\n",
        "    print(most_common_language[0][0])\n",
        "else:\n",
        "    print(\"No language data found.\")\n"
      ],
      "metadata": {
        "id": "CUYs-83xECB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6 Which programming language is the second most popular among users who joined after 2020?\n",
        "Language"
      ],
      "metadata": {
        "id": "sYInz7b-DB-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the list to store programming languages\n",
        "languages = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    # Iterate through the rows in the CSV\n",
        "    for row in reader:\n",
        "        # Parse the created_at field\n",
        "        created_at = row.get('created_at', '').strip()\n",
        "\n",
        "        # Convert the date string to a datetime object\n",
        "        if created_at:\n",
        "            user_join_date = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "            # Check if the user joined after 2020\n",
        "            if user_join_date.year > 2020:\n",
        "                # Get the language field and clean it up\n",
        "                language = row.get('language', '').strip()\n",
        "                if language:\n",
        "                    languages.append(language)\n",
        "\n",
        "# Count the occurrence of each language\n",
        "language_counts = Counter(languages)\n",
        "\n",
        "# Find the two most common languages\n",
        "most_common_languages = language_counts.most_common(2)\n",
        "\n",
        "# Print the second most common language\n",
        "if len(most_common_languages) >= 2:\n",
        "    print(most_common_languages[1][0])  # Second most common language\n",
        "else:\n",
        "    print(\"Not enough language data found.\")\n"
      ],
      "metadata": {
        "id": "O2SiPqQfECh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tk9n-EV6Csov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7 Which language has the highest average number of stars per repository?\n",
        "Language"
      ],
      "metadata": {
        "id": "M8gOsaFcDI0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "# Define a dictionary to store total stars and repository count per language\n",
        "language_stats = defaultdict(lambda: {'stars': 0, 'repos': 0})\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        # Get the language and stargazers_count field\n",
        "        language = row.get('language', '').strip()\n",
        "        stars = row.get('stargazers_count', '0').strip()\n",
        "\n",
        "        # Only process if language and stars are available\n",
        "        if language and stars.isdigit():\n",
        "            language_stats[language]['stars'] += int(stars)\n",
        "            language_stats[language]['repos'] += 1\n",
        "\n",
        "# Calculate average stars for each language\n",
        "average_stars_per_language = {\n",
        "    language: stats['stars'] / stats['repos']\n",
        "    for language, stats in language_stats.items()\n",
        "    if stats['repos'] > 0\n",
        "}\n",
        "\n",
        "# Find the language with the highest average stars\n",
        "if average_stars_per_language:\n",
        "    most_popular_language = max(average_stars_per_language, key=average_stars_per_language.get)\n",
        "    print(most_popular_language)\n",
        "else:\n",
        "    print(\"No language data found.\")\n"
      ],
      "metadata": {
        "id": "4B2sxYyQDMw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8 Let's define leader_strength as followers / (1 + following). Who are the top 5 in terms of leader_strength? List their login in order, comma-separated.\n",
        "User login"
      ],
      "metadata": {
        "id": "W-DbpJ5RDN1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define a list to store users and their leader strength\n",
        "leader_strengths = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        # Get followers and following counts\n",
        "        followers = int(row.get('followers', 0).strip())\n",
        "        following = int(row.get('following', 0).strip())\n",
        "\n",
        "        # Calculate leader strength\n",
        "        leader_strength = followers / (1 + following)\n",
        "\n",
        "        # Store the user's login and their leader strength\n",
        "        leader_strengths.append((row.get('login', ''), leader_strength))\n",
        "\n",
        "# Sort users by leader strength in descending order\n",
        "leader_strengths.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Get the top 5 users\n",
        "top_5_leaders = [login for login, strength in leader_strengths[:5]]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(','.join(top_5_leaders))\n"
      ],
      "metadata": {
        "id": "zIkF5aU4EEcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.9 What is the correlation between the number of followers and the number of public repositories among users in Delhi?\n",
        "Correlation between followers and repos (to 3 decimal places, e.g. 0.123 or -0.123)"
      ],
      "metadata": {
        "id": "OtT1PGcNDR1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Lists to store the followers and public repos of users from Delhi\n",
        "followers = []\n",
        "public_repos = []\n",
        "\n",
        "# Open the users.csv file and read data\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        # Filter for users in Delhi\n",
        "        location = row.get('location', '').strip().lower()\n",
        "        if \"delhi\" in location:\n",
        "            # Get followers and public repositories values\n",
        "            try:\n",
        "                followers_count = int(row['followers'])\n",
        "                public_repos_count = int(row['public_repos'])\n",
        "\n",
        "                # Append the valid values to the lists\n",
        "                followers.append(followers_count)\n",
        "                public_repos.append(public_repos_count)\n",
        "            except ValueError:\n",
        "                # Skip rows with invalid numerical values\n",
        "                continue\n",
        "\n",
        "# Ensure there is data to compute correlation\n",
        "if len(followers) > 1 and len(public_repos) > 1:\n",
        "    # Compute Pearson correlation coefficient\n",
        "    correlation_matrix = np.corrcoef(followers, public_repos)\n",
        "    correlation = correlation_matrix[0, 1]\n",
        "    # Output correlation rounded to 3 decimal places\n",
        "    print(f\"{correlation:.3f}\")\n",
        "else:\n",
        "    print(\"Insufficient data for correlation calculation.\")\n"
      ],
      "metadata": {
        "id": "O4qQLNDeEFbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.10 Does creating more repos help users get more followers? Using regression, estimate how many additional followers a user gets per additional public repository.\n",
        "Regression slope of followers on repos (to 3 decimal places, e.g. 0.123 or -0.123)"
      ],
      "metadata": {
        "id": "T6aahVvgDVNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Lists to store the followers and public repos of users from Delhi\n",
        "followers = []\n",
        "public_repos = []\n",
        "\n",
        "# Open the users.csv file and read data\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        # Filter for users in Delhi\n",
        "        location = row.get('location', '').strip().lower()\n",
        "        if \"delhi\" in location:\n",
        "            # Get followers and public repositories values\n",
        "            try:\n",
        "                followers_count = int(row['followers'])\n",
        "                public_repos_count = int(row['public_repos'])\n",
        "\n",
        "                # Append the valid values to the lists\n",
        "                followers.append(followers_count)\n",
        "                public_repos.append(public_repos_count)\n",
        "            except ValueError:\n",
        "                # Skip rows with invalid numerical values\n",
        "                continue\n",
        "\n",
        "# Ensure there is data for regression\n",
        "if len(followers) > 1 and len(public_repos) > 1:\n",
        "    # Perform linear regression: followers ~ public_repos\n",
        "    slope, intercept = np.polyfit(public_repos, followers, 1)\n",
        "\n",
        "    # Output the slope rounded to 3 decimal places\n",
        "    print(f\"{slope:.3f}\")\n",
        "else:\n",
        "    print(\"Insufficient data for regression.\")\n"
      ],
      "metadata": {
        "id": "8k-Y3a-QEGEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.11 Do people typically enable projects and wikis together? What is the correlation between a repo having projects enabled and having wiki enabled?\n",
        "Correlation between projects and wiki enabled (to 3 decimal places, e.g. 0.123 or -0.123)"
      ],
      "metadata": {
        "id": "rukbnOMiDZU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file = 'repositories.csv'  # Replace with the correct path\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to boolean if necessary\n",
        "df['has_projects'] = df['has_projects'].astype(bool)\n",
        "df['has_wiki'] = df['has_wiki'].astype(bool)\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(df['has_projects'], df['has_wiki'])\n",
        "\n",
        "# Perform Chi-Square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-Square Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n"
      ],
      "metadata": {
        "id": "eNe6ZUGlEGo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.12 Do hireable users follow more people than those who are not hireable?\n",
        "Average of following per user for hireable=true minus the average following for the rest (to 3 decimal places, e.g. 12.345 or -12.345)"
      ],
      "metadata": {
        "id": "DA1wuAUPDcdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def analyze_following_difference(users_csv_path='users.csv'):\n",
        "    # Read the data\n",
        "    df = pd.read_csv(users_csv_path)\n",
        "\n",
        "    # Calculate average following for hireable users\n",
        "    hireable_following = df[df['hireable'] == True]['following'].mean()\n",
        "\n",
        "    # Calculate average following for non-hireable users\n",
        "    non_hireable_following = df[df['hireable'] != True]['following'].mean()\n",
        "\n",
        "    # Calculate the difference rounded to 3 decimal places\n",
        "    difference = round(hireable_following - non_hireable_following, 3)\n",
        "\n",
        "    # Print debug information\n",
        "    print(f\"Number of hireable users: {len(df[df['hireable'] == True])}\")\n",
        "    print(f\"Number of non-hireable users: {len(df[df['hireable'] != True])}\")\n",
        "    print(f\"Average following for hireable users: {hireable_following:.3f}\")\n",
        "    print(f\"Average following for non-hireable users: {non_hireable_following:.3f}\")\n",
        "\n",
        "    return difference\n",
        "\n",
        "# Calculate the difference\n",
        "result = analyze_following_difference()\n",
        "print(f\"\\nDifference in average following: {result:.3f}\")"
      ],
      "metadata": {
        "id": "G_P1pCMpEHUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.13 Some developers write long bios. Does that help them get more followers? What's the impact of the length of their bio (in Unicode words, split by whitespace) with followers? (Ignore people without bios)\n",
        "Regression slope of followers on bio word count (to 3 decimal places, e.g. 12.345 or -12.345)"
      ],
      "metadata": {
        "id": "JIoHrPRrDg9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "def analyze_bio_followers_correlation(users_csv_path='users.csv'):\n",
        "    # Read the data\n",
        "    df = pd.read_csv(users_csv_path)\n",
        "\n",
        "    # Filter out rows without bios\n",
        "    df = df[df['bio'].notna() & (df['bio'] != '')]\n",
        "\n",
        "    # Calculate bio length in Unicode characters\n",
        "    df['bio_length'] = df['bio'].str.len()\n",
        "\n",
        "    # Prepare data for regression\n",
        "    X = df['bio_length'].values.reshape(-1, 1)\n",
        "    y = df['followers'].values\n",
        "\n",
        "    # Perform linear regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Get the slope rounded to 3 decimal places\n",
        "    slope = round(model.coef_[0], 3)\n",
        "\n",
        "    # Print debug information\n",
        "    print(f\"Number of users with bios: {len(df)}\")\n",
        "    print(f\"Bio length range: {df['bio_length'].min()} to {df['bio_length'].max()}\")\n",
        "    print(f\"Followers range: {df['followers'].min()} to {df['followers'].max()}\")\n",
        "    print(f\"R-squared: {model.score(X, y):.3f}\")\n",
        "\n",
        "    return slope\n",
        "\n",
        "# Calculate the regression slope\n",
        "result = analyze_bio_followers_correlation()\n",
        "print(f\"\\nRegression slope: {result:.3f}\")"
      ],
      "metadata": {
        "id": "pon5eL1wEHvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.14 Who created the most repositories on weekends (UTC)? List the top 5 users' login in order, comma-separated\n",
        "Users login"
      ],
      "metadata": {
        "id": "rbwLtQJFDlkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "# Counter to store the number of repositories created by each user on weekends\n",
        "weekend_repo_counts = Counter()\n",
        "\n",
        "# Open the repositories.csv file and read data\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        created_at = row.get('created_at', '')\n",
        "        if created_at:\n",
        "            # Convert created_at string to a datetime object\n",
        "            created_date = datetime.fromisoformat(created_at[:-1])  # Remove 'Z' and convert\n",
        "\n",
        "            # Check if the day is Saturday (5) or Sunday (6)\n",
        "            if created_date.weekday() in [5, 6]:\n",
        "                user_login = row['login']\n",
        "                weekend_repo_counts[user_login] += 1  # Increment the count for the user\n",
        "\n",
        "# Get the top 5 users who created the most repositories on weekends\n",
        "top_users = weekend_repo_counts.most_common(5)\n",
        "\n",
        "# Extract the logins of the top users\n",
        "top_logins = [user[0] for user in top_users]\n",
        "\n",
        "# Output the top users' logins as a comma-separated string\n",
        "print(','.join(top_logins))\n"
      ],
      "metadata": {
        "id": "omVZR-aqEIRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.15 Do people who are hireable share their email addresses more often?\n",
        "[fraction of users with email when hireable=true] minus [fraction of users with email for the rest] (to 3 decimal places, e.g. 0.123 or -0.123)"
      ],
      "metadata": {
        "id": "2dnXBFzkDosl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def analyze_email_sharing(users_csv_path='users.csv'):\n",
        "    # Read the complete CSV file\n",
        "    df = pd.read_csv(users_csv_path)\n",
        "\n",
        "    # Convert email column to boolean (True if email exists, False if NaN or empty)\n",
        "    df['has_email'] = df['email'].notna() & (df['email'] != '')\n",
        "\n",
        "    # Calculate for hireable users\n",
        "    hireable_mask = df['hireable'] == True\n",
        "    if hireable_mask.any():\n",
        "        hireable_email_fraction = df[hireable_mask]['has_email'].mean()\n",
        "    else:\n",
        "        hireable_email_fraction = 0\n",
        "\n",
        "    # Calculate for non-hireable users\n",
        "    non_hireable_mask = df['hireable'] != True\n",
        "    if non_hireable_mask.any():\n",
        "        non_hireable_email_fraction = df[non_hireable_mask]['has_email'].mean()\n",
        "    else:\n",
        "        non_hireable_email_fraction = 0\n",
        "\n",
        "    # Calculate difference and round to 3 decimal places\n",
        "    difference = round(hireable_email_fraction - non_hireable_email_fraction, 3)\n",
        "\n",
        "    # Print debug information\n",
        "    print(f\"Total users: {len(df)}\")\n",
        "    print(f\"Hireable users with email: {df[hireable_mask]['has_email'].sum()}/{hireable_mask.sum()}\")\n",
        "    print(f\"Non-hireable users with email: {df[non_hireable_mask]['has_email'].sum()}/{non_hireable_mask.sum()}\")\n",
        "    print(f\"Hireable fraction: {hireable_email_fraction:.3f}\")\n",
        "    print(f\"Non-hireable fraction: {non_hireable_email_fraction:.3f}\")\n",
        "\n",
        "    return difference\n",
        "\n",
        "# Read and analyze the complete dataset\n",
        "result = analyze_email_sharing()\n",
        "print(f\"\\nFinal result: {result:.3f}\")"
      ],
      "metadata": {
        "id": "HzNFgS0kEJUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.16 Let's assume that the last word in a user's name is their surname (ignore missing names, trim and split by whitespace.) What's the most common surname? (If there's a tie, list them all, comma-separated, alphabetically)\n",
        "Most common surname(s)"
      ],
      "metadata": {
        "id": "A2A0WC8vDtTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Counter to store surname frequencies\n",
        "surname_counter = Counter()\n",
        "\n",
        "# Open the users.csv file and read data\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        name = row.get('name', '').strip()\n",
        "        if name:  # Ignore missing names\n",
        "            # Split the name by whitespace and get the last word as the surname\n",
        "            surname = name.split()[-1]\n",
        "            surname_counter[surname] += 1\n",
        "\n",
        "# Find the maximum frequency of surnames\n",
        "if surname_counter:\n",
        "    max_count = max(surname_counter.values())\n",
        "    # Get all surnames with the maximum frequency\n",
        "    most_common_surnames = [surname for surname, count in surname_counter.items() if count == max_count]\n",
        "    # Sort surnames alphabetically\n",
        "    most_common_surnames.sort()\n",
        "    # Output the result\n",
        "    print(f\"{', '.join(most_common_surnames)}: {max_count}\")\n",
        "else:\n",
        "    print(\"No names found.\")\n"
      ],
      "metadata": {
        "id": "E7Jpy0oZEJs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVnYgqzPDyDP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}